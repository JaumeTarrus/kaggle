{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319fd29c",
   "metadata": {},
   "source": [
    "## Model One\n",
    "\n",
    "First attempt to build a ML model for the Kaggle Titanic competion. After exploring the data seems like the main features to consider are Sex and Pclass. After that the family related features SibSp and Parch also seem to have some effect onsurvival rates which is related to children having a a higher survial rate. Age only seems relevant in the bracket corresponding to children. Fare besides strongly correlated to Pclass, it also seems to correlate to families, in the sense that inside the same Pclass famileies are paying a higher fare per passanger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c72df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, impute, tree\n",
    "from sklearn.experimental import enable_iterative_imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04325d",
   "metadata": {},
   "source": [
    "Since the number of features is fairly limited and most of them are categorical a decision tree seems to be a good model to use. For the cateforical features we will use a One Hot encoder. For SibSp and Parch we only consider to categories (i.e. family or no family). Fare and age are discretized. We disregard the rest of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2368dc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Load Train date\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "#Apply the encoders\n",
    "x = np.array(train[['Sex']])\n",
    "enc = preprocessing.OneHotEncoder(drop='if_binary', handle_unknown ='ignore')\n",
    "p1 = enc.fit_transform(x).toarray()\n",
    "\n",
    "x = np.array(train[['Pclass','Embarked']])\n",
    "enc = preprocessing.OneHotEncoder(drop='if_binary', handle_unknown ='ignore', max_categories=3)\n",
    "p2 = enc.fit_transform(x).toarray()\n",
    "\n",
    "x = np.array(train[['SibSp','Parch']])\n",
    "enc = preprocessing.OneHotEncoder(drop='if_binary', handle_unknown ='ignore', max_categories = 2)\n",
    "p3 = enc.fit_transform(x).toarray()\n",
    "\n",
    "x = np.array(train[['Fare']])\n",
    "enc = preprocessing.KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "p4 = enc.fit_transform(x)\n",
    "\n",
    "# We asign -10 for missing age values to create its own category\n",
    "imp = impute.SimpleImputer(missing_values=np.nan, strategy='constant', fill_value = -10)\n",
    "x = imp.fit_transform(np.array(train[['Age']]))\n",
    "enc = preprocessing.KBinsDiscretizer(n_bins=9, encode='ordinal', strategy='uniform')\n",
    "p5 = enc.fit_transform(x)\n",
    "\n",
    "#Put all the encoded data together and train the model\n",
    "x = np.hstack((p1,p2,p3,p4,p5))\n",
    "y = np.array(train[['Survived']])\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy').fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7625f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Encode the test data features as before\n",
    "\n",
    "x = np.array(test[['Sex']])\n",
    "enc = preprocessing.OneHotEncoder(drop='if_binary', handle_unknown ='ignore')\n",
    "p1 = enc.fit_transform(x).toarray()\n",
    "\n",
    "x = np.array(test[['Pclass','Embarked']])\n",
    "enc = preprocessing.OneHotEncoder(drop='if_binary', handle_unknown ='ignore', max_categories=3)\n",
    "p2 = enc.fit_transform(x).toarray()\n",
    "\n",
    "x = np.array(test[['SibSp','Parch']])\n",
    "enc = preprocessing.OneHotEncoder(drop='if_binary', handle_unknown ='ignore', max_categories = 2)\n",
    "p3 = enc.fit_transform(x).toarray()\n",
    "\n",
    "#Assign missing values of age with an IterativeImputer\n",
    "imp = impute.IterativeImputer(missing_values=np.nan)\n",
    "x = imp.fit_transform(np.array(test[['Fare']]))\n",
    "enc = preprocessing.KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "p4 = enc.fit_transform(x)\n",
    "\n",
    "imp = impute.SimpleImputer(missing_values=np.nan, strategy='constant', fill_value = -10)\n",
    "x = imp.fit_transform(np.array(test[['Age']]))\n",
    "enc = preprocessing.KBinsDiscretizer(n_bins=9, encode='ordinal', strategy='uniform')\n",
    "p5 = enc.fit_transform(x)\n",
    "\n",
    "# Put the test data together and predict outcomes using the model we have trained\n",
    "x = np.hstack((p1,p2,p3,p4,p5))\n",
    "pred = clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9332743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create file to submit  to Kaggle\n",
    "\n",
    "test['Survived']= pred\n",
    "test[['PassengerId','Survived']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e064737",
   "metadata": {},
   "source": [
    "This model achieved an accuracy of 0.74641."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d5143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
